{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nnfllab1usingpreprocessmobilenet.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rivHRVqWTABa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"27f017ca-5b23-4038-80a1-0bb6e94af741","executionInfo":{"status":"ok","timestamp":1541445071283,"user_tz":-330,"elapsed":13122,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize \n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn't guaranteed\n","gpu = GPUs[0]\n","\n","def printm():\n","  process = psutil.Process(os.getpid())\n","  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","\n","printm()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 11.5 GB  I Proc size: 138.5 MB\n","GPU RAM Free: 3044MB | Used: 8397MB | Util  73% | Total 11441MB\n"],"name":"stdout"}]},{"metadata":{"id":"i6opP8q-TJSf","colab_type":"code","colab":{}},"cell_type":"code","source":["import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GJBJEDr_Tad2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cee8f562-5516-442d-e911-0f08b7d9c92d","executionInfo":{"status":"ok","timestamp":1541445083750,"user_tz":-330,"elapsed":3791,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"LZn5q2CZTcUv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"ef36e19f-7749-4029-b339-cee8dc735347","executionInfo":{"status":"ok","timestamp":1541425321388,"user_tz":-330,"elapsed":66081,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#4/XwCmdKiWvbvVtpA_jh7vPaL1kqdreQE7s6dR7oocs6Jzb0GsuiaxJ5w"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"-N1HGkpRTfVd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ee1704c5-977c-403e-f628-3042380d1721","executionInfo":{"status":"ok","timestamp":1541445089641,"user_tz":-330,"elapsed":4024,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"DoDuA6LuUJBd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4d5fd0b7-a321-437f-e270-b8d476c5e632","executionInfo":{"status":"ok","timestamp":1541445090968,"user_tz":-330,"elapsed":1117,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["cd drive"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"ec0QxTDBULRv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f2787657-a6fb-48b6-9e34-1835294e3d18","executionInfo":{"status":"ok","timestamp":1541445094510,"user_tz":-330,"elapsed":3071,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["ls"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"enQ68XjkUNQu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6f9fdd9b-b6b9-414e-9512-ef790e63a7c5","executionInfo":{"status":"ok","timestamp":1541445095803,"user_tz":-330,"elapsed":1112,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["cd My Drive"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"metadata":{"id":"DC-sc6OXUPm3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1389},"outputId":"ec972d94-3afd-49b1-c6cc-c44207966a0b","executionInfo":{"status":"ok","timestamp":1541445099179,"user_tz":-330,"elapsed":3028,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["ls"],"execution_count":9,"outputs":[{"output_type":"stream","text":[" 1stone.h5\n"," 20151122_223055.mp4\n","'AAA-Literature reviews:.gdoc'\n"," AAARBI.gdoc\n","'AAA SOP Progress.gdoc'\n","'AAA stopwords.gdoc'\n","'AA BAV Project.gdoc'\n","'Aa bavv2.gdoc'\n"," ABC.xlsx\n"," ans.csv\n"," ASD.gdoc\n"," bidirectional42i.h5\n"," bidirectionalffhai.h5\n"," bidirectional.h5\n"," bidirectionalhai.h5\n"," bidirectionalwithoutglobal.h5\n"," \u001b[0m\u001b[01;34mCNN_Data\u001b[0m/\n","\u001b[01;34m'Colab Notebooks'\u001b[0m/\n"," companies.docx\n","'Copy of glove.twitter.27B.100d.txt'\n","'Copy of glove.twitter.27B.50d.txt'\n"," datarnn.csv\n"," DESCRIPTION.docx\n"," DESCRIPTION.gdoc\n","'dna structure1.ppt'\n","'DRM Ass 2.2.xlsx'\n","'DRM Ass 2.2.xlsx.gsheet'\n"," \u001b[01;34mdt\u001b[0m/\n"," GAIL_Group37_Futures.xlsx\n"," GAIL_Group37_Futures.xlsx.gsheet\n","'GAIL_Group37_Underlying Asset.xlsx'\n","'GAIL_Group37_Underlying Asset.xlsx.gsheet'\n"," GANs.zip\n"," GroceryProcessed.csv\n","'Ian Goodfellow, Yoshua Bengio, Aaron Courville-Deep Learning-MIT Press (2016).pdf'\n","'Ideas and constrains of the strategies.gdoc'\n"," inc_occ_gender.csv\n"," instructions_1.pdf\n","'log returns.xlsx'\n"," lstmheading.csv\n"," marketdata_sample.csv\n"," master.csv\n"," MAY.xlsx\n"," MAY.xlsx.gsheet\n"," model_mnist.h5\n","\u001b[01;34m'my doc'\u001b[0m/\n"," new_file.csv\n"," new_file.gsheet\n"," newresults.csv\n"," news_sample.csv\n","\u001b[01;34m'NNFL Lab1'\u001b[0m/\n"," \u001b[01;34mnnfllab1data\u001b[0m/\n","'orientation details.pptx'\n"," page.doc\n"," page.doc.gdoc\n","'PS Journal.gdoc'\n"," report.gdoc\n"," Report.gdoc\n","'Resume (1).gdoc'\n"," Resume.gdoc\n"," sample_submission.csv\n"," sample_train.csv\n"," Schedule.gsheet\n"," ShubhranshJagota.pdf\n"," SP100_OM_Data.rar\n"," test.csv\n"," test_labels.csv\n"," testrr.csv\n"," train.csv\n"," train.gsheet\n"," \u001b[01;34mTraining\u001b[0m/\n"," training.1600000.processed.noemoticon.csv\n"," traintoxic.csv\n","'tut on pipe and dup.gdoc'\n","'Untitled spreadsheet.gsheet'\n"," with_symbol2.csv\n"," with_symbol3.csv\n"," with_symbol4.csv\n"," withsymbol.csv\n"],"name":"stdout"}]},{"metadata":{"id":"mfTeKthIURKz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"51994400-9e82-4622-a761-ec850bb32639","executionInfo":{"status":"ok","timestamp":1541445102630,"user_tz":-330,"elapsed":3313,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["import numpy\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.utils import np_utils\n","from keras import backend as K\n","K.set_image_dim_ordering('th')\n","import keras\n","import keras.backend as K\n","import numpy as np\n","import pandas as pd\n","import math\n","import cv2\n","from keras import layers\n","from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n","from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n","from keras.models import Model, Sequential\n","from keras.preprocessing import image\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"2WO6kpMlUrSu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f74c1d9a-9379-484d-863f-5e4292dcf9c0","executionInfo":{"status":"ok","timestamp":1541445104052,"user_tz":-330,"elapsed":1263,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["cd dt"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/dt\n"],"name":"stdout"}]},{"metadata":{"id":"nbMzOeTHUzXI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"50dc7faf-e706-4e64-bb3a-46e9e961d55a","executionInfo":{"status":"ok","timestamp":1541445108633,"user_tz":-330,"elapsed":4467,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["ls"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mcat\u001b[0m/    \u001b[01;34mdandelion\u001b[0m/  \u001b[01;34mdonuts\u001b[0m/   \u001b[01;34mmonkey\u001b[0m/    \u001b[01;34mpizza\u001b[0m/    \u001b[01;34mrose\u001b[0m/   \u001b[01;34msquirrel\u001b[0m/   \u001b[01;34mtulip\u001b[0m/\n","\u001b[01;34mdaisy\u001b[0m/  \u001b[01;34mdog\u001b[0m/        \u001b[01;34mlasagna\u001b[0m/  \u001b[01;34mpancakes\u001b[0m/  \u001b[01;34mrisotto\u001b[0m/  \u001b[01;34msalad\u001b[0m/  \u001b[01;34msunflower\u001b[0m/\n"],"name":"stdout"}]},{"metadata":{"id":"Tu1ehp97U-n3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"db18ca86-ecb0-46d3-ab76-ec5faebcea1d","executionInfo":{"status":"ok","timestamp":1541445110049,"user_tz":-330,"elapsed":1226,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["cd .."],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"metadata":{"id":"WSJixYJ_J9D6","colab_type":"code","colab":{}},"cell_type":"code","source":["keras.backend.set_image_data_format('channels_last')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U_2ZQBdHU0Na","colab_type":"code","colab":{}},"cell_type":"code","source":["train_dir = 'dt'\n","image_size = 224\n","nTrain = 5149\n","nVal = 1277\n","train_steps = nTrain//32\n","vaid_steps = nVal//32"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6H44bkEyVBVQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"outputId":"c6cfdf7d-7cec-4aa7-cb21-01d69869a1fd","executionInfo":{"status":"ok","timestamp":1541445116331,"user_tz":-330,"elapsed":2481,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=True, \n","                                   featurewise_std_normalization=False, samplewise_std_normalization=True, \n","                                   zca_whitening=True, zca_epsilon=1e-06, rotation_range=45, width_shift_range=0.2, \n","                                   height_shift_range=0.2, brightness_range=None, shear_range=0.2, zoom_range=0.2, \n","                                   channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=True, \n","                                   vertical_flip=True, rescale=1./255, preprocessing_function=None, data_format=None, \n","                                   validation_split=0.2)\n","\n","train_set = train_datagen.flow_from_directory(train_dir, target_size=(image_size, image_size), color_mode='rgb', classes=None, \n","                                              class_mode='categorical', batch_size=32, shuffle=True, seed=None, \n","                                              save_to_dir=None, save_prefix='', save_format='png', follow_links=False, \n","                                              subset='training', interpolation='nearest')\n","validation_generator = train_datagen.flow_from_directory(train_dir, target_size=(image_size, image_size),\n","                                                         batch_size=32, class_mode='categorical', subset='validation')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:645: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"],"name":"stderr"},{"output_type":"stream","text":["Found 5149 images belonging to 15 classes.\n","Found 1277 images belonging to 15 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"mpZ0ui3DHsxq","colab_type":"code","colab":{}},"cell_type":"code","source":["keras.backend.set_image_data_format('channels_last')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uBHNkYoQVF4w","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications.mobilenet import MobileNet\n","mob_net= MobileNet(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RSD9JyJJHdF3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1684},"outputId":"9f6481a7-6dc1-4793-d2e4-cda9bdefd03b","executionInfo":{"status":"ok","timestamp":1541445129585,"user_tz":-330,"elapsed":1405,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["for layer in mob_net.layers[:-4]:\n","    layer.trainable = False\n"," \n"," # Check the trainable status of the individual layers\n","for layer in mob_net.layers:\n","    print(layer, layer.trainable)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["<keras.engine.topology.InputLayer object at 0x7ff0770c7f98> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff0bc784d68> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff0bc784da0> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0bc784cf8> False\n","<keras.layers.core.Activation object at 0x7ff077060c18> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff077060710> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff075042fd0> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff077060a58> False\n","<keras.layers.core.Activation object at 0x7ff074fe6a20> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff074f69dd8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff074f69c18> False\n","<keras.layers.core.Activation object at 0x7ff074eb8eb8> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff074e23e80> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff074def0b8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff074e65e10> False\n","<keras.layers.core.Activation object at 0x7ff074dc2be0> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff074d65cc0> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff074d65080> False\n","<keras.layers.core.Activation object at 0x7ff074d464e0> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff074c677b8> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff074cc0780> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff074bcb2e8> False\n","<keras.layers.core.Activation object at 0x7ff074b49710> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff074b725f8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff074ad8d30> False\n","<keras.layers.core.Activation object at 0x7ff074a8deb8> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff074a60d68> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff074a1b898> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff074abaf98> False\n","<keras.layers.core.Activation object at 0x7ff074992c50> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff0749b3f28> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0749b3080> False\n","<keras.layers.core.Activation object at 0x7ff07493e240> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff074895f28> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff0748b49e8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff07485b7b8> False\n","<keras.layers.core.Activation object at 0x7ff0706caef0> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff0706f3898> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0706f32e8> False\n","<keras.layers.core.Activation object at 0x7ff0706510b8> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff0705cab00> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff0705cac18> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0705952e8> False\n","<keras.layers.core.Activation object at 0x7ff0705b2ef0> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff0704d5be0> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0704d5320> False\n","<keras.layers.core.Activation object at 0x7ff07042ccc0> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff0703d6b70> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff0703d6ba8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0703809e8> False\n","<keras.layers.core.Activation object at 0x7ff070332fd0> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff0702d9b38> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0702d90b8> False\n","<keras.layers.core.Activation object at 0x7ff0702bb390> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff0701d5668> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff070235630> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff0701bd128> False\n","<keras.layers.core.Activation object at 0x7ff0701fd630> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff07013de80> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff070098f98> False\n","<keras.layers.core.Activation object at 0x7ff070011f60> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff05f7fbd68> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff07003ef28> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff07003e4a8> False\n","<keras.layers.core.Activation object at 0x7ff05f715ef0> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff05f73bdd8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f646198> False\n","<keras.layers.core.Activation object at 0x7ff05f69d940> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff05f63b908> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff05f540f98> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f618be0> False\n","<keras.layers.core.Activation object at 0x7ff05f521860> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff05f4c4748> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f4c4198> False\n","<keras.layers.core.Activation object at 0x7ff05f4a39b0> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff05f423b38> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff05f423b70> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f3e1198> False\n","<keras.layers.core.Activation object at 0x7ff05f383908> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff05f2c9da0> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f321588> False\n","<keras.layers.core.Activation object at 0x7ff05f278b70> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff05f21fa20> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff05f21fa58> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f1cb978> False\n","<keras.layers.core.Activation object at 0x7ff05f103ef0> False\n","<keras.layers.convolutional.Conv2D object at 0x7ff05f1239e8> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05f1230b8> False\n","<keras.layers.core.Activation object at 0x7ff05f0885f8> False\n","<keras.layers.convolutional.ZeroPadding2D object at 0x7ff05f027518> False\n","<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff05f0004e0> False\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05efcb438> False\n","<keras.layers.core.Activation object at 0x7ff05ef04e48> True\n","<keras.layers.convolutional.Conv2D object at 0x7ff05ef2a7f0> True\n","<keras.layers.normalization.BatchNormalization object at 0x7ff05ef2a240> True\n","<keras.layers.core.Activation object at 0x7ff05ee8ba20> True\n"],"name":"stdout"}]},{"metadata":{"id":"_VyPrxiGIQyj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"410b98fe-0a79-440a-87bb-55ad013a8e48","executionInfo":{"status":"ok","timestamp":1541445133787,"user_tz":-330,"elapsed":3858,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["!cat $HOME/.keras/keras.json"],"execution_count":20,"outputs":[{"output_type":"stream","text":["{\n","    \"floatx\": \"float32\",\n","    \"epsilon\": 1e-07,\n","    \"backend\": \"tensorflow\",\n","    \"image_data_format\": \"channels_last\"\n","}"],"name":"stdout"}]},{"metadata":{"id":"mIX3FvodH1dF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":312},"outputId":"05c32376-ea20-4fea-969f-a52c9ac3de8e","executionInfo":{"status":"ok","timestamp":1541450534205,"user_tz":-330,"elapsed":4524,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["from keras import models\n","from keras import layers\n","from keras import optimizers\n"," \n","# Create the model\n","model = models.Sequential()\n"," \n","# Add the vgg convolutional base model\n","model.add(mob_net)\n"," \n","# Add new layers\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(15, activation='softmax'))\n"," \n","# Show a summary of the model. Check the number of trainable parameters\n","model.summary()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 50176)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               6422656   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 15)                1935      \n","=================================================================\n","Total params: 9,653,455\n","Trainable params: 7,475,215\n","Non-trainable params: 2,178,240\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"eqVfduG4H5-C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":975},"outputId":"e1ab625c-2a85-4c63-93b0-57b4eaa22ffa","executionInfo":{"status":"ok","timestamp":1541450502721,"user_tz":-330,"elapsed":5361657,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["# Compile the model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.99),\n","              metrics=['acc'])\n","# Train the model\n","history = model.fit_generator(\n","      train_set,\n","      steps_per_epoch=train_steps ,\n","      epochs=25,\n","      validation_data=validation_generator,\n","      validation_steps=vaid_steps,\n","      verbose=1)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:799: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n","/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:817: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 234s 1s/step - loss: 2.3474 - acc: 0.4992 - val_loss: 0.8868 - val_acc: 0.6955\n","Epoch 2/25\n","160/160 [==============================] - 242s 2s/step - loss: 1.0930 - acc: 0.6392 - val_loss: 0.9112 - val_acc: 0.6923\n","Epoch 3/25\n","160/160 [==============================] - 239s 1s/step - loss: 0.9525 - acc: 0.6860 - val_loss: 0.7372 - val_acc: 0.7444\n","Epoch 4/25\n","160/160 [==============================] - 240s 2s/step - loss: 0.8691 - acc: 0.7087 - val_loss: 0.7807 - val_acc: 0.7204\n","Epoch 5/25\n","160/160 [==============================] - 240s 2s/step - loss: 0.7969 - acc: 0.7278 - val_loss: 0.7160 - val_acc: 0.7684\n","Epoch 6/25\n","160/160 [==============================] - 234s 1s/step - loss: 0.7841 - acc: 0.7412 - val_loss: 0.7180 - val_acc: 0.7636\n","Epoch 7/25\n","160/160 [==============================] - 247s 2s/step - loss: 0.7316 - acc: 0.7564 - val_loss: 0.6805 - val_acc: 0.7676\n","Epoch 8/25\n","160/160 [==============================] - 233s 1s/step - loss: 0.6998 - acc: 0.7680 - val_loss: 0.6661 - val_acc: 0.7732\n","Epoch 9/25\n","160/160 [==============================] - 246s 2s/step - loss: 0.6911 - acc: 0.7686 - val_loss: 0.7891 - val_acc: 0.7388\n","Epoch 10/25\n","160/160 [==============================] - 245s 2s/step - loss: 0.6684 - acc: 0.7888 - val_loss: 0.8435 - val_acc: 0.7260\n","Epoch 11/25\n","160/160 [==============================] - 230s 1s/step - loss: 0.6511 - acc: 0.7864 - val_loss: 0.7270 - val_acc: 0.7636\n","Epoch 12/25\n","160/160 [==============================] - 246s 2s/step - loss: 0.6477 - acc: 0.7907 - val_loss: 0.7612 - val_acc: 0.7556\n","Epoch 13/25\n","160/160 [==============================] - 228s 1s/step - loss: 0.6047 - acc: 0.8039 - val_loss: 0.7535 - val_acc: 0.7788\n","Epoch 14/25\n","160/160 [==============================] - 231s 1s/step - loss: 0.6012 - acc: 0.8010 - val_loss: 0.8302 - val_acc: 0.7508\n","Epoch 15/25\n","160/160 [==============================] - 232s 1s/step - loss: 0.5709 - acc: 0.8127 - val_loss: 0.6978 - val_acc: 0.7812\n","Epoch 16/25\n","160/160 [==============================] - 231s 1s/step - loss: 0.5901 - acc: 0.8061 - val_loss: 0.8145 - val_acc: 0.7476\n","Epoch 17/25\n","160/160 [==============================] - 236s 1s/step - loss: 0.5516 - acc: 0.8206 - val_loss: 0.7721 - val_acc: 0.7668\n","Epoch 18/25\n","160/160 [==============================] - 232s 1s/step - loss: 0.5228 - acc: 0.8224 - val_loss: 0.6474 - val_acc: 0.7973\n","Epoch 19/25\n","160/160 [==============================] - 236s 1s/step - loss: 0.5453 - acc: 0.8170 - val_loss: 0.9578 - val_acc: 0.7324\n","Epoch 20/25\n","160/160 [==============================] - 213s 1s/step - loss: 0.5121 - acc: 0.8293 - val_loss: 0.7685 - val_acc: 0.7788\n","Epoch 21/25\n","160/160 [==============================] - 128s 803ms/step - loss: 0.5385 - acc: 0.8130 - val_loss: 0.6805 - val_acc: 0.7724\n","Epoch 22/25\n","160/160 [==============================] - 126s 787ms/step - loss: 0.4922 - acc: 0.8390 - val_loss: 0.7392 - val_acc: 0.7708\n","Epoch 23/25\n","160/160 [==============================] - 137s 859ms/step - loss: 0.4949 - acc: 0.8313 - val_loss: 0.7259 - val_acc: 0.7788\n","Epoch 24/25\n","160/160 [==============================] - 130s 812ms/step - loss: 0.4887 - acc: 0.8369 - val_loss: 0.8718 - val_acc: 0.7516\n","Epoch 25/25\n","160/160 [==============================] - 123s 771ms/step - loss: 0.4839 - acc: 0.8362 - val_loss: 0.8155 - val_acc: 0.7628\n"],"name":"stdout"}]},{"metadata":{"id":"Z3f0I5MUZYNb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":627},"outputId":"1cef600e-d466-42b8-ae0f-071386647b25","executionInfo":{"status":"ok","timestamp":1541434480038,"user_tz":-330,"elapsed":2260414,"user":{"displayName":"SHUBHRANSH JAGOTA","photoUrl":"","userId":"16444133890155128473"}}},"cell_type":"code","source":["history = model.fit_generator(\n","      train_set,\n","      steps_per_epoch=train_steps ,\n","      epochs=15,\n","      validation_data=validation_generator,\n","      validation_steps=vaid_steps,\n","      verbose=1)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:799: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n","/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:817: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"],"name":"stderr"},{"output_type":"stream","text":["160/160 [==============================] - 139s 869ms/step - loss: 0.6548 - acc: 0.8280 - val_loss: 1.1523 - val_acc: 0.7708\n","Epoch 2/15\n","160/160 [==============================] - 133s 833ms/step - loss: 0.6297 - acc: 0.8329 - val_loss: 1.1110 - val_acc: 0.7708\n","Epoch 3/15\n","160/160 [==============================] - 131s 821ms/step - loss: 0.6736 - acc: 0.8296 - val_loss: 1.5570 - val_acc: 0.7244\n","Epoch 4/15\n","160/160 [==============================] - 141s 883ms/step - loss: 0.6367 - acc: 0.8368 - val_loss: 1.1970 - val_acc: 0.7692\n","Epoch 5/15\n","160/160 [==============================] - 136s 853ms/step - loss: 0.6836 - acc: 0.8261 - val_loss: 1.3181 - val_acc: 0.7460\n","Epoch 6/15\n","160/160 [==============================] - 139s 869ms/step - loss: 0.6758 - acc: 0.8218 - val_loss: 1.3368 - val_acc: 0.7452\n","Epoch 7/15\n","160/160 [==============================] - 121s 758ms/step - loss: 0.6415 - acc: 0.8401 - val_loss: 0.9427 - val_acc: 0.7909\n","Epoch 8/15\n","160/160 [==============================] - 124s 776ms/step - loss: 0.6345 - acc: 0.8350 - val_loss: 1.0087 - val_acc: 0.7949\n","Epoch 9/15\n","160/160 [==============================] - 126s 786ms/step - loss: 0.6840 - acc: 0.8288 - val_loss: 1.1848 - val_acc: 0.7845\n","Epoch 10/15\n","160/160 [==============================] - 141s 878ms/step - loss: 0.6458 - acc: 0.8462 - val_loss: 1.1456 - val_acc: 0.7668\n","Epoch 11/15\n","160/160 [==============================] - 122s 764ms/step - loss: 0.6552 - acc: 0.8321 - val_loss: 1.1438 - val_acc: 0.7796\n","Epoch 12/15\n","160/160 [==============================] - 135s 845ms/step - loss: 0.6263 - acc: 0.8366 - val_loss: 1.2275 - val_acc: 0.7708\n","Epoch 13/15\n","160/160 [==============================] - 219s 1s/step - loss: 0.6006 - acc: 0.8386 - val_loss: 1.5710 - val_acc: 0.7324\n","Epoch 14/15\n","160/160 [==============================] - 226s 1s/step - loss: 0.6445 - acc: 0.8349 - val_loss: 1.4280 - val_acc: 0.7412\n","Epoch 15/15\n","160/160 [==============================] - 224s 1s/step - loss: 0.6135 - acc: 0.8413 - val_loss: 1.3967 - val_acc: 0.7380\n"],"name":"stdout"}]},{"metadata":{"id":"BAkmatI3H-nw","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save('nnfllab1mobilent.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"szAhy7h7Ovet","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}